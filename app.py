import streamlit as st
import google.generativeai as genai
import PyPDF2
import os
import datetime # ì‹œê°„ ê¸°ë¡ìš©

st.title("ğŸ“„ Muna E. Teacher")

# =========================================================
# [ì„¤ì •] ì½ì–´ì•¼ í•  íŒŒì¼ë“¤ì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸(ëª©ë¡)ë¡œ ì ìœ¼ì„¸ìš”!
# =========================================================
TARGET_FILES = ["lesson.pdf"] 

# 1. ì‚¬ì´ë“œë°”: API í‚¤ ê´€ë¦¬
with st.sidebar:
    if "GEMINI_API_KEY" in st.secrets:
        api_key = st.secrets["GEMINI_API_KEY"]
    else:
        api_key = st.text_input("Gemini API Key", type="password")

# 2. ì„œë²„ì— ìˆëŠ” PDF íŒŒì¼ë“¤ ì½ê¸°
pdf_content = ""
for file_name in TARGET_FILES:
    if os.path.exists(file_name):
        try:
            with open(file_name, "rb") as f:
                pdf_reader = PyPDF2.PdfReader(f)
                file_text = ""
                for page in pdf_reader.pages:
                    file_text += page.extract_text() + "\n"
                pdf_content += f"\n--- [íŒŒì¼: {file_name}] ---\n{file_text}\n"
        except Exception:
            pass # ì—ëŸ¬ ë¬´ì‹œ

# 3. ì±—ë´‡ ì„±ê²© ì„¤ì •
if pdf_content:
    SYSTEM_PROMPT = f"""
    [ë‹¹ì‹ ì˜ ì—­í• ]
    ë‹¹ì‹ ì€ ê³ ë“±í•™êµ ì˜ì–´ ì„ ìƒë‹˜ 'Muna E. Teacher'ì…ë‹ˆë‹¤. 
    ì•„ë˜ [ìˆ˜ì—… ìë£Œ]ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìƒì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
    [ìˆ˜ì—… ìë£Œ] {pdf_content}
    """
else:
    SYSTEM_PROMPT = "ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤."

# 4. Gemini ì—°ê²°
if not api_key:
    st.warning("API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()

genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-1.5-flash") # ë¹ ë¥¸ ëª¨ë¸ ì¶”ì²œ

# 5. ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "Hi! ì§ˆë¬¸ì´ ìˆë‹ˆ?"}]

# 6. í™”ë©´ ì¶œë ¥
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# 7. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # â˜…â˜…â˜… [CCTV í•µì‹¬ ì½”ë“œ] ì„ ìƒë‹˜ ëª°ë˜ë³´ê¸° ê¸°ëŠ¥ â˜…â˜…â˜…
    # í•™ìƒì´ ì§ˆë¬¸ì„ ë˜ì§€ë©´, ì„œë²„ ê¸°ë¡(ë¡œê·¸)ì— ì‹œê°„ì„ ì°ì–´ì„œ ì¶œë ¥í•©ë‹ˆë‹¤.
    now = datetime.datetime.now().strftime("%Hì‹œ %Më¶„")
    print(f"\n[ğŸ‘€ í•™ìƒ ì§ˆë¬¸ ê°ì§€ - {now}] --------------------")
    print(f"ğŸ“ ë‚´ìš©: {prompt}")
    print("--------------------------------------------------\n")

    # ë¬¸ë§¥ ì •ë¦¬
    full_prompt = SYSTEM_PROMPT + "\n\n"
    recent_messages = st.session_state.messages[-10:] 
    for msg in recent_messages:
        role = "User" if msg["role"] == "user" else "Model"
        full_prompt += f"{role}: {msg['content']}\n"
    
    # ë‹µë³€ ìƒì„±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        try:
            responses = model.generate_content(full_prompt, stream=True)
            for response in responses:
                if response.text:
                    full_response += response.text
                    message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")

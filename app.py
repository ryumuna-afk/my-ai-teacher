import streamlit as st
import google.generativeai as genai

# 1. ì œëª© ì„¤ì •
st.title("ğŸ¤– ìš°ë¦¬ ë°˜ AI ì„ ìƒë‹˜")

# 2. ê¸ˆê³ (Secrets)ì—ì„œ ë¹„ë°€ë²ˆí˜¸ êº¼ë‚´ì˜¤ê¸°
# (í•™ìƒë“¤ ëˆˆì—ëŠ” ì´ ê³¼ì •ì´ ì•ˆ ë³´ì…ë‹ˆë‹¤!)
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except FileNotFoundError:
    st.error("ì„ ìƒë‹˜! ì„œë²„ì— í‚¤ê°€ ë“±ë¡ë˜ì§€ ì•Šì•˜ì–´ìš”. Secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# 3. Gemini ì—°ê²°í•˜ê¸°
genai.configure(api_key=api_key)
model = genai.GenerativeModel("models/gemini-pro-latest")

# 4. ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ì•ˆë…•? ë‚˜ëŠ” AI ì„ ìƒë‹˜ì´ì•¼. ë¬´ì—‡ì„ ë„ì™€ì¤„ê¹Œ?"}]

# 5. ì´ì „ ëŒ€í™” í™”ë©´ì— ë³´ì—¬ì£¼ê¸°
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# 6. í•™ìƒ ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    # í•™ìƒ ì§ˆë¬¸ í‘œì‹œ
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # AIì—ê²Œ ì§ˆë¬¸ ì „ë‹¬ì„ ìœ„í•œ ë¬¸ë§¥ ì •ë¦¬
    full_prompt = "ë„ˆëŠ” ì¹œì ˆí•œ ê³ ë“±í•™êµ ì˜ì–´ êµì‚¬ì•¼. ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì— ë§ì¶°ì„œ ì‰½ê³  ì¬ë¯¸ìˆê²Œ ì„¤ëª…í•´ ì¤˜."
    for msg in st.session_state.messages:
        role = "User" if msg["role"] == "user" else "Model"
        full_prompt += f"{role}: {msg['content']}\n"
    
    try:
        # AI ë‹µë³€ ìƒì„±
        response = model.generate_content(full_prompt)
        msg = response.text
        
        # ë‹µë³€ í‘œì‹œ
        st.chat_message("assistant").write(msg)
        st.session_state.messages.append({"role": "assistant", "content": msg})
        
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš” ã… ã… : {e}")


import streamlit as st
import google.generativeai as genai
from datetime import datetime

# ==========================================
# [ì„¤ì • 0] í˜„ì¬ ì‹œê°„ê³¼ ê³„ì ˆ ê³„ì‚°
# ==========================================
now = datetime.now()
current_date = now.strftime("%Yë…„ %mì›” %dì¼")

# ==========================================
# [ì„¤ì • 1] ì˜ì–´ ì„ ìƒë‹˜ í˜ë¥´ì†Œë‚˜ (ì„±ê²©) ì„¤ì •
# ==========================================
SYSTEM_PROMPT = f"""
[ê¸°ë³¸ ì •ë³´]
- ì˜¤ëŠ˜ì€ {current_date}ì…ë‹ˆë‹¤.
- ë‹¹ì‹ ì€ ê³ ë“±í•™êµ 1í•™ë…„ í•™ìƒë“¤ì„ ê°€ë¥´ì¹˜ëŠ” ì—´ì •ì ì´ê³  ì¹œì ˆí•œ 'ì˜ì–´ ì„ ìƒë‹˜'ì…ë‹ˆë‹¤.
- ì¸í„°ë„· ê²€ìƒ‰ì€ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

[í–‰ë™ ì§€ì¹¨]
1. ì„¤ëª…ì€ 'í•œêµ­ì–´'ë¡œ í•˜ë˜, ì˜ˆë¬¸ì€ ë°˜ë“œì‹œ 'ì˜ì–´'ë¡œ ë³´ì—¬ì£¼ì„¸ìš”.
2. í•™ìƒì´ ë¬¸ë²•ì´ë‚˜ ë‹¨ì–´ë¥¼ ë¬¼ì–´ë³´ë©´, ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì— ë§ëŠ” ìœ ì˜ì–´(Synonym)ë‚˜ ë°˜ì˜ì–´ë¥¼ í•˜ë‚˜ì”© ë§ë¶™ì—¬ ì£¼ì„¸ìš”. (ê¿€íŒì²˜ëŸ¼!)
3. í•™ìƒì´ ì˜ì–´ ë¬¸ì¥ì„ ì…ë ¥í•˜ë©´, ë” ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ êµì •(Correction)í•´ì£¼ê³  ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.
4. ë§íˆ¬ëŠ” ì¹œê·¼í•˜ê²Œ í•´ìš”. (ì˜ˆ: "ì´ê±´ ì‹œí—˜ì— ìì£¼ ë‚˜ì˜¤ëŠ” ê±°ì•¼!", "ì•„ì£¼ ì¢‹ì€ ì§ˆë¬¸ì´ì•¼! ğŸ‘")
5. ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì†”ì§íˆ ëª¨ë¥¸ë‹¤ê³  í•˜ê³ , í•¨ê»˜ ì°¾ì•„ë³´ìê³  ê²©ë ¤í•˜ì„¸ìš”.
"""

st.title("ğŸ‡ºğŸ‡¸ ìš°ë¦¬ ë°˜ ì˜ì–´ ìŒ¤ (AI)")

# 1. ê¸ˆê³ ì—ì„œ í‚¤ êº¼ë‚´ê¸°
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except FileNotFoundError:
    st.error("ì„œë²„ì— í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. Streamlit Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

genai.configure(api_key=api_key)
model = genai.GenerativeModel("models/gemini-pro-latest")

# 2. ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": f"Hi there! ğŸ‘‹ ì˜ì–´ ê³µë¶€í•˜ë‹¤ ë§‰íˆëŠ” ê±° ìˆë‹ˆ? ë¬¸ë²•, ë…í•´, ì‘ë¬¸ ë‹¤ ë¬¼ì–´ë´!"}]

# 3. ì´ì „ ëŒ€í™” í™”ë©´ì— ì¶œë ¥
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# 4. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì˜ì–´ ì§ˆë¬¸ì´ë‚˜ í•´ì„í•˜ê³  ì‹¶ì€ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ & ì €ì¥
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ë¬¸ë§¥ ì •ë¦¬
    full_prompt = SYSTEM_PROMPT + "\n\n"
    
    # ìµœê·¼ ëŒ€í™” 10ê°œë§Œ ê¸°ì–µ
    recent_messages = st.session_state.messages[-10:] 
    
    for msg in recent_messages:
        role = "User" if msg["role"] == "user" else "Model"
        full_prompt += f"{role}: {msg['content']}\n"
    
    # ë‹µë³€ ìƒì„± (íƒ€ì ì¹˜ëŠ” íš¨ê³¼)
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        try:
            responses = model.generate_content(full_prompt, stream=True)
            
            for response in responses:
                if response.text:
                    full_response += response.text
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë‚¬ì–´ìš”: {e}")

import streamlit as st
import google.generativeai as genai

# ==========================================
# [ì„¤ì • 1] ì±—ë´‡ì˜ ì„±ê²© (ì—¬ê¸°ë§Œ ê³ ì¹˜ë©´ ì±—ë´‡ì´ ë°”ë€ë‹ˆë‹¤!)
# ==========================================
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ê³ ë“±í•™êµ í•™ìƒë“¤ì„ ê°€ë¥´ì¹˜ëŠ” ì¹œì ˆí•˜ê³  ìœ ë¨¸ëŸ¬ìŠ¤í•œ 'ì˜ì–´ ì „ë¬¸ê°€' ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì›ì¹™ì„ ì§€ì¼œì„œ ëŒ€ë‹µí•˜ì„¸ìš”:
1. í•™ìƒ ìˆ˜ì¤€ì— ë§ì¶°ì„œ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•œë‹¤.
2. ë„ˆë¬´ ë”±ë”±í•˜ì§€ ì•Šê²Œ, ê°€ë”ì€ ì´ëª¨ì§€(ğŸ—ï¸, ğŸ§±)ë¥¼ ì‚¬ìš©í•œë‹¤.
3. ë‹µë³€ì€ 3~4ë¬¸ì¥ ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ í•µì‹¬ë§Œ ë§í•œë‹¤.
4. ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì†”ì§íˆ ëª¨ë¥¸ë‹¤ê³  í•œë‹¤.
"""

st.title("ğŸ—ï¸ Muna E. Teacher")

# 1. ê¸ˆê³ ì—ì„œ í‚¤ êº¼ë‚´ê¸°
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except FileNotFoundError:
    st.error("ì„œë²„ì— í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. Streamlit Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

genai.configure(api_key=api_key)
model = genai.GenerativeModel("models/gemini-pro-latest")

# 2. ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ì•ˆë…•! ê±´ì¶• ì•ˆì „ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²Œ ìˆë‹ˆ? ì„ ìƒë‹˜ì´ ì•Œë ¤ì¤„ê²Œ!"}]

# 3. ì´ì „ ëŒ€í™” í™”ë©´ì— ì¶œë ¥
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# 4. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ & ì €ì¥
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ==========================================
    # [í•µì‹¬ ì—…ê·¸ë ˆì´ë“œ] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ë¬¸ë§¥ ì •ë¦¬
    # ==========================================
    full_prompt = SYSTEM_PROMPT + "\n\n" # ì„±ê²©ì„ ê°€ì¥ ë¨¼ì € ì£¼ì…
    
    # ìµœê·¼ ëŒ€í™” 10ê°œë§Œ ê¸°ì–µí•˜ê²Œ í•˜ê¸° (ì†ë„ í–¥ìƒ íŒ!)
    recent_messages = st.session_state.messages[-10:] 
    
    for msg in recent_messages:
        role = "User" if msg["role"] == "user" else "Model"
        full_prompt += f"{role}: {msg['content']}\n"
    
    # ==========================================
    # [í•µì‹¬ ì—…ê·¸ë ˆì´ë“œ] íƒ€ì ì¹˜ë“¯ì´ ì¶œë ¥í•˜ê¸° (Streaming)
    # ==========================================
    with st.chat_message("assistant"):
        message_placeholder = st.empty() # ë¹ˆ ê³µê°„ì„ ë§Œë“¦
        full_response = ""

        try:
            # stream=True ì˜µì…˜ì´ í•µì‹¬! í•œ ê¸€ìì”© ë°›ì•„ì˜µë‹ˆë‹¤.
            responses = model.generate_content(full_prompt, stream=True)
            
            for response in responses:
                if response.text:
                    full_response += response.text
                    # í•œ ê¸€ìì”© ì¶”ê°€ë  ë•Œë§ˆë‹¤ í™”ë©´ì„ ê°±ì‹ 
                    message_placeholder.markdown(full_response + "â–Œ")
            
            # ë‹¤ ëë‚˜ë©´ ì»¤ì„œ(â–Œ) ì œê±°í•˜ê³  ìµœì¢…ë³¸ í™•ì •
            message_placeholder.markdown(full_response)
            
            # ëŒ€í™” ê¸°ë¡ì— ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë‚¬ì–´ìš”: {e}")
